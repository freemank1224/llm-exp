# ã€Œç¥žå¥‡çš„çŒœè¯å°èƒ½æ‰‹ã€â€”â€” ç»™å­©å­çš„äº’åŠ¨å¼å¤§è¯­è¨€æ¨¡åž‹ç§‘æ™®èŠ‚ç›®

è¿™æ˜¯ä¸€ä¸ªä¸ºæ²¡æœ‰AIåŸºç¡€çŸ¥è¯†çš„å°å­¦/ä¸­å­¦ç”Ÿè®²è§£å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰é¢„æµ‹åŽŸç†çš„äº’åŠ¨æ¼”ç¤ºé¡¹ç›®ã€‚æ—¨åœ¨é€šè¿‡äº¤äº’å¼é¡µé¢å’Œæ¼”ç¤ºæ¥è§£é‡ŠLLMçš„å·¥ä½œåŽŸç†ã€‚é‡‡ç”¨æ­¤é¡¹ç›®ï¼Œèƒ½å¤Ÿè¿œè¶…PPTçš„å®žæ—¶äº’åŠ¨æ¼”ç¤ºæ•ˆæžœï¼Œç”ŸåŠ¨çš„è®²è¿°LLMçš„ã€Œä¸‹ä¸€ä¸ªè¯å…ƒé¢„æµ‹ã€çš„å·¥ä½œæœºåˆ¶ã€‚

## 1. å®‰è£…è¯´æ˜Ž
æœ¬é¡¹ç›®æ”¯æŒä¸¤ç§å®‰è£…æ–¹å¼ï¼Œä¸€ä¸ªæ˜¯è‡ªå·±éƒ¨ç½²æœ¬åœ°çŽ¯å¢ƒï¼Œéœ€è¦ä½¿ç”¨`Conda`å‘½ä»¤æ¥å»ºç«‹å’Œå®ŒæˆPythonçš„åˆ›å»ºå’Œéƒ¨ç½²ï¼›å¦ä¸€ç§æ˜¯åŸºäºŽ`Docker`ï¼Œç›´æŽ¥æ‹‰å–é•œåƒå³å¯ä½¿ç”¨ã€‚ä¸‹é¢åˆ†åˆ«è¯´æ˜Žã€‚

### 1.1 ä½¿ç”¨ Conda 

#### MacOS ç”¨æˆ·ï¼ˆåº”è¯¥ä¹Ÿé€‚ç”¨äºŽUbuntuç”¨æˆ·ï¼Œä½†å¹¶æœªç»è¿‡éªŒè¯ï¼‰
1. ç”¨æˆ·è®¡ç®—æœºä¸­å¿…é¡»å­˜åœ¨CondaçŽ¯å¢ƒï¼Œå¦‚æžœæ²¡æœ‰ï¼Œéœ€è¦å…ˆå®‰è£… Miniconda æˆ– Anacondaï¼š
   è®¿é—® [Miniconda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/macos.html) æˆ– [Anaconda](https://www.anaconda.com/products/distribution) ä¸‹è½½é¡µé¢ï¼Œä¸‹è½½å¹¶æŒ‰ç…§è¯´æ˜Žå®‰è£…ã€‚
2. åˆ›å»ºæ–°çŽ¯å¢ƒå¹¶æ¿€æ´»ï¼š
   ```bash
   conda create --name llm-prediction python=3.10
   conda activate llm-prediction
   ```
3. å®‰è£…ä¾èµ–é¡¹ï¼š
   ```bash
   pip install -r requirements.txt
   ```

#### Windows ç”¨æˆ·
1. ç”¨æˆ·è®¡ç®—æœºä¸­å¿…é¡»å­˜åœ¨CondaçŽ¯å¢ƒï¼Œå¦‚æžœæ²¡æœ‰ï¼Œéœ€è¦å…ˆå®‰è£… Miniconda æˆ– Anacondaï¼š
   è®¿é—® [Miniconda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/windows.html) æˆ– [Anaconda](https://www.anaconda.com/products/distribution) ä¸‹è½½é¡µé¢ï¼Œä¸‹è½½å¹¶æŒ‰ç…§è¯´æ˜Žå®‰è£…ã€‚
2. åˆ›å»ºæ–°çŽ¯å¢ƒå¹¶æ¿€æ´»ï¼š
   ```bash
   conda create --name llm-prediction python=3.10
   conda activate llm-prediction
   ```
3. å®‰è£…ä¾èµ–é¡¹ï¼š
   ```bash
   pip install -r requirements_win.txt
   ```

### 1.2 ä½¿ç”¨ Docker
**ä½¿ç”¨Dockerçš„ä¼˜åŠ¿ï¼š**
- âœ… æ— éœ€å®‰è£…PythonçŽ¯å¢ƒå’Œä¾èµ–
- âœ… æ¨¡åž‹å·²é¢„ä¸‹è½½ï¼Œå¯åŠ¨å³å¯ä½¿ç”¨
- âœ… è·¨å¹³å°å…¼å®¹ï¼ˆWindows/macOS/Linuxï¼‰
- âœ… ä¸€é”®éƒ¨ç½²ï¼Œé¿å…çŽ¯å¢ƒé—®é¢˜

**å®‰è£… Docker çŽ¯å¢ƒ**
åœ¨ä½¿ç”¨ Docker æ–¹å¼ä¹‹å‰ï¼Œæ‚¨éœ€è¦å…ˆåœ¨è®¡ç®—æœºä¸Šå®‰è£… Docker Desktopï¼š

1. è®¿é—® [Docker Desktop å®˜ç½‘](https://www.docker.com/products/docker-desktop/) ä¸‹è½½é€‚åˆæ‚¨æ“ä½œç³»ç»Ÿçš„ Docker Desktop
2. æŒ‰ç…§å®‰è£…å‘å¯¼å®Œæˆå®‰è£…
3. å®‰è£…å®ŒæˆåŽå¯åŠ¨ Docker Desktop
4. ç­‰å¾… Docker å¼•æ“Žå®Œå…¨å¯åŠ¨ï¼ˆæ‰˜ç›˜å›¾æ ‡å˜ä¸ºè¿è¡ŒçŠ¶æ€ï¼‰

å®‰è£…å®ŒæˆåŽï¼Œæ‚¨å°±å¯ä»¥æŒ‰ç…§ä¸‹ä¸€èŠ‚ä¸­çš„æ­¥éª¤æ‹‰å–å’Œè¿è¡Œé¡¹ç›®é•œåƒäº†ã€‚

> **æ³¨æ„**ï¼šDocker Desktop æ”¯æŒ Windows 10/11 Pro/Enterprise/Education å’Œ macOS 10.15+ï¼Œå…¶ä»–ç³»ç»Ÿç‰ˆæœ¬å¯èƒ½éœ€è¦ä½¿ç”¨ Docker Toolbox æˆ–å…¶ä»–æ›¿ä»£æ–¹æ¡ˆã€‚

## 2. è¿è¡Œé¡¹ç›®

### 2.1 æœ¬åœ°PythonçŽ¯å¢ƒè¿è¡Œï¼ˆåœ¨1.1èŠ‚CondaçŽ¯å¢ƒé…ç½®å®Œæˆä¹‹åŽï¼‰
ä»¥ä¸‹æ­¥éª¤å¯¹äºŽWindowsç³»ç»Ÿè¿˜æ˜¯MacOSç³»ç»Ÿå‡é€‚ç”¨ã€‚åªä¸è¿‡MacOSæ˜¯åœ¨ç»ˆç«¯ï¼ˆTerminalï¼‰ä¸­æ‰§è¡Œï¼ŒWindowsæ˜¯åœ¨å‘½ä»¤æç¤ºç¬¦ï¼ˆAnaconda Promptï¼‰ä¸­æ‰§è¡Œã€‚

- æ¿€æ´»çŽ¯å¢ƒ
  ```bash
  conda activate llm-prediction
  ```

- åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•ä¸‹ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨åº”ç”¨ç¨‹åº
  ```bash
  cd ï½ž/Documents/llm-exp
  streamlit run Home.py
  ```

### 2.2 ä½¿ç”¨ Dockerï¼ˆå¯¹åº”1.2èŠ‚DockerçŽ¯å¢ƒé…ç½®å®Œæˆçš„æƒ…å†µï¼‰

#### ðŸš€ ä½¿ç”¨é¢„æž„å»ºé•œåƒ
```bash
# æ‹‰å–é¢„æž„å»ºçš„é•œåƒï¼ˆåŒ…å«æ¨¡åž‹ï¼‰
docker pull ghcr.io/freemank1224/llm-exp:latest

# è¿è¡Œå®¹å™¨
docker run -d -p 8501:8501 --name llm-prediction ghcr.io/freemank1224/llm-exp:latest

# è®¿é—®åº”ç”¨ï¼šhttp://localhost:8501
```

#### ðŸ”¨ æœ¬åœ°æž„å»ºé•œåƒ
å¦‚æžœæ‚¨è¦å°è¯•è‡ªå·±æž„å»ºé•œåƒï¼Œè¿™é‡Œåªåˆ—å‡ºåœ¨MacOSä¸‹çš„æž„å»ºæ–¹æ³•ï¼ˆLinuxå¯èƒ½ä¹Ÿé€‚ç”¨ï¼Œä½†æœªåšéªŒè¯ï¼‰ï¼Œå…¶å®ƒå¹³å°è¯·è‡ªè¡Œæœç´¢å’Œå°è¯•ï¼š
```bash
# å…‹éš†ä»“åº“
git clone https://github.com/freemank1224/llm-exp.git
cd llm-exp

# æž„å»ºé•œåƒï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡åž‹åˆ°é•œåƒä¸­ï¼‰
./build_docker.sh

# è¿è¡Œå®¹å™¨
./run_docker.sh
```






---
# ã€ŒMagic Token Predictorã€: An interactive course of LLM prediction principle for kids

This is an interactive demonstration project designed to explain the principles of Large Language Models (LLMs) to primary/secondary school students who have no AI background knowledge. It aims to explain how LLMs work through interactive pages and demonstrations. By utilizing this project, we can achieve real-time interactive demonstration effects far beyond PowerPoint presentations, vividly illustrating the "next token prediction" mechanism of LLMs.

## 1. Installation Instructions
This project supports two installation methods: one is to deploy the local environment yourself, which requires using `Conda` commands to create and deploy Python; the other is based on `Docker`, where you can directly pull the image to use. The following explains each method separately.

### 1.1 Using Conda

#### macOS Users (should also apply to Ubuntu users, but not verified)
1. The user's computer must have a Conda environment. If not, you need to install Miniconda or Anaconda first:
   Visit the [Miniconda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/macos.html) or [Anaconda](https://www.anaconda.com/products/distribution) download page, download, and follow the instructions to install.
2. Create and activate a new environment:
   ```bash
   conda create --name llm-prediction python=3.10
   conda activate llm-prediction
   ```
3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

#### Windows Users
1. The user's computer must have a Conda environment. If not, you need to install Miniconda or Anaconda first:
   Visit the [Miniconda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/windows.html) or [Anaconda](https://www.anaconda.com/products/distribution) download page, download, and follow the instructions to install.
2. Create and activate a new environment:
   ```bash
   conda create --name llm-prediction python=3.10
   conda activate llm-prediction
   ```
3. Install dependencies:
   ```bash
   pip install -r requirements_win.txt
   ```

### 1.2 Using Docker
**Advantages of using Docker:**
- âœ… No need to install Python environment and dependencies
- âœ… Models are pre-downloaded, ready to use on startup
- âœ… Cross-platform compatibility (Windows/macOS/Linux)
- âœ… One-click deployment, avoiding environment issues

**Installing Docker Environment**
Before using Docker, you need to install Docker Desktop on your computer:

1. Visit [Docker Desktop Official Website](https://www.docker.com/products/docker-desktop/) to download Docker Desktop for your operating system
2. Complete the installation following the installation wizard
3. Launch Docker Desktop after installation
4. Wait for the Docker engine to fully start (tray icon shows running status)

After installation is complete, you can follow the steps in the next section to pull and run the project image.

> **Note**: Docker Desktop supports Windows 10/11 Pro/Enterprise/Education and macOS 10.15+. Other system versions may need to use Docker Toolbox or other alternatives.

## 2. Running the Project

### 2.1 Local Python Environment (After completing Conda environment configuration in Section 1.1)
The following steps apply to both Windows and macOS systems. The only difference is that macOS executes in Terminal, while Windows executes in Command Prompt (Anaconda Prompt).

- Activate environment
  ```bash
  conda activate llm-prediction
  ```

- Switch to the project directory and run the following command to start the application
  ```bash
  cd ~/Documents/llm-exp
  streamlit run Home.py
  ```

### 2.2 Using Docker (Corresponding to Docker environment configuration completed in Section 1.2)

#### ðŸš€ Using Pre-built Image
```bash
# Pull the pre-built image (with models included)
docker pull ghcr.io/freemank1224/llm-exp:latest

# Run container
docker run -d -p 8501:8501 --name llm-prediction ghcr.io/freemank1224/llm-exp:latest

# Access the app: http://localhost:8501
```

#### ðŸ”¨ Build Image Locally
If you want to try building the image yourself, here only lists the build method for macOS (Linux may also apply, but not verified). For other platforms, please search and try by yourself:
```bash
# Clone repository
git clone https://github.com/freemank1224/llm-exp.git
cd llm-exp

# Build image (automatically downloads models into the image)
./build_docker.sh

# Run container
./run_docker.sh
```

import streamlit as st
from model import LLMPredictor
import time

def main():
    # å°†æ¨¡å‹å®ä¾‹å­˜å‚¨åœ¨ session state ä¸­
    if 'predictor' not in st.session_state:
        st.session_state.predictor = LLMPredictor()

    st.title("ä¸‹ä¸€ä¸ªè¯å…ƒé¢„æµ‹æ¼”ç¤º")
    st.subheader("è‹±æ–‡æ¨¡å‹ï¼šGPT-2ï¼Œä¸­æ–‡æ¨¡å‹ï¼šQwen2-1.5Bï¼ŒTop-Ké‡‡æ ·")

    # åˆå§‹åŒ–å…¶ä»– session state
    if 'generated_text' not in st.session_state:
        st.session_state.generated_text = ""  # åˆå§‹åŒ–ä¸ºç©ºå­—ç¬¦ä¸²
    if 'default_prompts' not in st.session_state:
        st.session_state.default_prompts = {
            "ä¸­æ–‡": "è¯·è¾“å…¥ä¸­æ–‡æ–‡æœ¬",
            "è‹±æ–‡": "Please input English text"
        }
    if 'is_auto_mode' not in st.session_state:
        st.session_state.is_auto_mode = False
    if 'is_running' not in st.session_state:
        st.session_state.is_running = False
    if 'predicting' not in st.session_state:
        st.session_state.predicting = False
    if 'temperature' not in st.session_state:
        st.session_state.temperature = 1.0
    if 'top_k' not in st.session_state:
        st.session_state.top_k = 5
    if 'token_len' not in st.session_state:
        st.session_state.token_len = 0
    if 'model_lang' not in st.session_state:
        st.session_state.model_lang = "ä¸­æ–‡"
    if 'selected_token' not in st.session_state:
        st.session_state.selected_token = None  # æ–°å¢ï¼šè¿½è¸ªé€‰ä¸­çš„token
    if 'generation_interval' not in st.session_state:
        st.session_state.generation_interval = 0.5  # æ·»åŠ é»˜è®¤ç”Ÿæˆé—´éš”

    # æ·»åŠ è®¾ç½®åŒºåŸŸ
    with st.sidebar:
        st.header("æ¨¡å‹è®¾ç½®")
        
        # å¤ä½æŒ‰é’® - ç°åœ¨åªæ¸…ç©ºæ–‡æœ¬è€Œä¸æ˜¯è®¾ç½®å›ºå®šå€¼
        if st.button("æ¸…ç©ºæ–‡æœ¬", type="primary"):
            st.session_state.generated_text = ""
            st.session_state.is_running = False
            st.session_state.predicting = False
            st.rerun()

        # åˆ†éš”çº¿
        st.divider()
        
        # è‡ªåŠ¨/æ‰‹åŠ¨æ¨¡å¼åˆ‡æ¢
        st.session_state.is_auto_mode = st.toggle("è‡ªåŠ¨æ¨¡å¼", value=st.session_state.is_auto_mode)
        
        if st.session_state.is_auto_mode:
            # è‡ªåŠ¨æ¨¡å¼çš„å¯åŠ¨/åœæ­¢æ§åˆ¶
            if not st.session_state.is_running:
                if st.button("å¼€å§‹è‡ªåŠ¨ç”Ÿæˆ"):
                    st.session_state.is_running = True
                    st.rerun()
            else:
                if st.button("åœæ­¢ç”Ÿæˆ"):
                    st.session_state.is_running = False
                    st.rerun()
            
            # ä¿®æ”¹ç”Ÿæˆé€Ÿåº¦æ§åˆ¶çš„å®ç°
            generation_interval = st.slider(
                "ç”Ÿæˆé—´éš” (ç§’)",
                min_value=0.1,
                max_value=2.0,
                value=st.session_state.generation_interval,
                step=0.1,
                key="interval_slider",
                help="æ¯ä¸ªtokenç”Ÿæˆä¹‹é—´çš„æ—¶é—´é—´éš”"
            )
            # ç¡®ä¿æ›´æ–°åˆ° session state
            if generation_interval != st.session_state.generation_interval:
                st.session_state.generation_interval = generation_interval

        # æ¨¡å‹è¯­è¨€é€‰æ‹©
        try:
            model_lang = st.selectbox(
                "é€‰æ‹©æ¨¡å‹è¯­è¨€",
                ["ä¸­æ–‡", "è‹±æ–‡"],
                index=0 if st.session_state.model_lang == "ä¸­æ–‡" else 1
            )
            if model_lang != st.session_state.model_lang:
                with st.spinner(f"æ­£åœ¨åˆ‡æ¢åˆ°{model_lang}æ¨¡å‹..."):
                    st.session_state.model_lang = model_lang
                    if not st.session_state.generated_text.strip():  # åªåœ¨æ–‡æœ¬ä¸ºç©ºæ—¶æ˜¾ç¤ºæç¤º
                        st.session_state.generated_text = st.session_state.default_prompts[model_lang]
                    # é‡ç½®é¢„æµ‹çŠ¶æ€
                    st.session_state.predicting = False
                    st.session_state.is_running = False
                    st.rerun()

        except Exception as e:
            st.error(f"æ¨¡å‹åˆ‡æ¢å¤±è´¥: {str(e)}")

        # æ¸©åº¦æ§åˆ¶
        st.session_state.temperature = st.slider(
            "æ¸©åº¦ (Temperature)",
            min_value=0.1,
            max_value=2.0,
            value=st.session_state.temperature,
            step=0.1,
            help="è¾ƒé«˜çš„æ¸©åº¦ä¼šäº§ç”Ÿæ›´å¤šæ ·åŒ–çš„è¾“å‡ºï¼Œè¾ƒä½çš„æ¸©åº¦ä¼šäº§ç”Ÿæ›´ç¡®å®šæ€§çš„è¾“å‡º"
        )

        st.session_state.top_k = st.slider(
            "Top-K é‡‡æ ·",
            min_value=1,
            max_value=20,
            value=st.session_state.top_k,
            step=1,
            help="åœ¨è¯è¡¨ä¸­é€‰æ‹©æ’åœ¨æœ€å‰çš„Kä¸ªè¯"
        )

        # åˆ†å‰²çº¿
        st.divider()

        # è¯åº“é•¿åº¦æ˜¾ç¤º
        try:
            if st.session_state.model_lang == "ä¸­æ–‡":
                token_len = (st.session_state.predictor.zh_tokenizer.vocab_size 
                           if st.session_state.predictor.zh_tokenizer is not None 
                           else "æ¨¡å‹æœªåŠ è½½")
            else:
                token_len = (st.session_state.predictor.en_tokenizer.vocab_size 
                           if st.session_state.predictor.en_tokenizer is not None 
                           else "æ¨¡å‹æœªåŠ è½½")
            
            # æ›´æ–°session stateä¸­çš„token_len
            st.session_state.token_len = token_len
        except Exception as e:
            st.session_state.token_len = "æ— æ³•è·å–è¯è¡¨å¤§å°"
            st.error(f"è·å–è¯è¡¨å¤§å°æ—¶å‡ºé”™: {str(e)}")

        st.markdown("#### è¯åº“çš„é•¿åº¦")  # Using markdown for black text
        st.text_area(
            "",  # Remove label since we're using markdown above
            value=str(st.session_state.token_len),  # Ensure value is string
            disabled=True,
            height=100,
            key="vocab_size_area",
            label_visibility="collapsed",  # Hide empty label
        )
        # Apply custom CSS to increase text size
        st.markdown("""
            <style>
            div[data-testid="stTextArea"] textarea {
                font-size: 1.2em;
            }
            </style>
            """, unsafe_allow_html=True)

    # æ–‡æœ¬æ˜¾ç¤ºåŒºåŸŸï¼Œæ·»åŠ æœ€å¤§é•¿åº¦é™åˆ¶
    if len(st.session_state.generated_text) > 1000:  # é˜²æ­¢ç”Ÿæˆæ–‡æœ¬è¿‡é•¿
        st.warning("æ–‡æœ¬å·²è¾¾åˆ°æœ€å¤§é•¿åº¦é™åˆ¶ï¼Œè¯·ç‚¹å‡»å¤ä½æŒ‰é’®å¼€å§‹æ–°çš„ç”Ÿæˆ")
        st.session_state.is_running = False
        st.session_state.predicting = False

    # ä¿®æ”¹é¢„æµ‹é€»è¾‘ï¼Œæ·»åŠ æ¸©åº¦å‚æ•°
    def update_predictions():
        try:
            result = st.session_state.predictor.generate_next_token(
                input_text=st.session_state.generated_text,
                temperature=st.session_state.temperature,
                model_lang=st.session_state.model_lang,
                top_k=st.session_state.top_k
            )
            
            if not result:
                st.error("é¢„æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹åŠ è½½çŠ¶æ€")
                return

            st.subheader("å€™é€‰ Tokens åŠå…¶æ¦‚ç‡ï¼š")
            
            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
            for pred in result['predictions']:
                token = pred['token']
                prob = pred['probability']
                is_sampled = pred.get('is_sampled', True)  # è·å–æ˜¯å¦è¢«é‡‡æ ·é€‰ä¸­
                
                # åˆ›å»ºä¸€ä¸ªå¸¦æœ‰èƒŒæ™¯è‰²çš„åˆ—å¸ƒå±€
                col_style = "background-color: #90EE90;" if is_sampled else ""
                cols = st.columns([2, 6, 2])
                with cols[0]:
                    if is_sampled:
                        st.markdown(f"**:green[Token: {token}]** ğŸ¯")
                    else:
                        st.write(f"Token: {token}")
                with cols[1]:
                    progress_container = st.container()
                    with progress_container:
                        progress_bar = st.progress(0)
                        progress_bar.progress(prob)
                with cols[2]:
                    if is_sampled:
                        st.markdown(f"**:green[{prob:.5f}]**")
                    else:
                        st.write(f"{prob:.5f}")
                    if not st.session_state.is_auto_mode:
                        if st.button("é€‰æ‹©", key=f"use_{token}", help=f"ç‚¹å‡»å°†'{token}'æ·»åŠ åˆ°æ–‡æœ¬ä¸­"):
                            st.session_state.generated_text += token
                            st.rerun()

            if st.session_state.is_auto_mode and st.session_state.is_running:
                candidates = result['predictions']
                selected_token = [item['token'] for item in candidates if item['is_sampled']][0]
                st.session_state.selected_token = selected_token  # æ›´æ–°é€‰ä¸­çš„token
                st.session_state.generated_text += selected_token
                
                # æ·»åŠ é€‰ä¸­æç¤º
                st.success(f"å·²é€‰æ‹©Token: {selected_token}")
                
                time.sleep(st.session_state.generation_interval)
                st.rerun()

        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
            st.write("Error details:", str(e))
            st.session_state.is_running = False
            st.session_state.predicting = False

    # æ–‡æœ¬æ˜¾ç¤ºåŒºåŸŸ
    new_text = st.text_area(
        "è¾“å…¥æ–‡æœ¬ï¼š",  # æ›´æ”¹æ ‡ç­¾æ›´æ˜ç¡®
        value=st.session_state.generated_text,
        height=100,
        key="text_input_area",
        placeholder=st.session_state.default_prompts[st.session_state.model_lang],  # æ·»åŠ å ä½ç¬¦æç¤º
        disabled=st.session_state.is_running or st.session_state.predicting
    )

    # ä»…å½“æ–‡æœ¬éç©ºæ—¶æ‰å…è®¸é¢„æµ‹
    if new_text.strip():
        # å¦‚æœæ–‡æœ¬è¢«ç”¨æˆ·ä¿®æ”¹ï¼Œæ›´æ–° session state
        if new_text != st.session_state.generated_text:
            st.session_state.generated_text = new_text
            st.session_state.predicting = False
            st.session_state.is_running = False

        # æ˜¾ç¤ºé¢„æµ‹æŒ‰é’®å’Œç»“æœ
        if st.session_state.is_auto_mode:
            st.info("å½“å‰å¤„äºè‡ªåŠ¨æ¨¡å¼")
            if st.session_state.is_running:
                st.success("æ­£åœ¨è‡ªåŠ¨ç”Ÿæˆä¸­...")
                update_predictions()
            else:
                st.warning("è‡ªåŠ¨ç”Ÿæˆå·²æš‚åœ")
        else:
            if st.button("é¢„æµ‹ä¸‹ä¸€ä¸ªè¯"):
                st.session_state.predicting = True
            
            if st.session_state.predicting:
                update_predictions()
    else:
        st.warning("è¯·å…ˆè¾“å…¥ä¸€äº›æ–‡æœ¬å†å¼€å§‹é¢„æµ‹")

if __name__ == '__main__':
    main()